=============
Code overview
=============

User interface
--------------

`Installing <installation.txt>`_ the :code:`bilby_pipe` module provides the
user with four command line programs:

1. `bilby_pipe <main.txt>`_
2. `bilby_pipe_generation <data_generation.txt>`_
3. `bilby_pipe_analysis <data_analysis.txt>`_
4. `bilby_pipe_create_injection_file <create_injections.txt>`_

For most users, only the first of these will be used in practise. In this
document, we'll give a brief overview of how these are used internally to
help developers orient themselves with the project.

Python Modules
--------------

At the top-level, the :code:`bilby_pipe` python package provides several
sub-modules as visualised here:

.. graphviz::

   digraph {
         "bilby_pipe" -> ".main";
         "bilby_pipe" -> ".data_generation";
         "bilby_pipe" -> ".data_analysis";
         "bilby_pipe" -> ".create_injections";
         "bilby_pipe" -> ".utils";
            }

each submodule (e.g., :code:`bilby_pipe.utils`) serves a different purpose.
On this page, we'll give a short description of the general code structure.
Specific details for different modules can then be found by following the
links in the `Submodules API`_.

Workflow
--------

The typical workflow for `bilby_pipe` is that a user calls the
:code:`bilby_pipe` command line tool giving it some "User input". Typically,
this is of the form of an `ini file <ini_file.txt>`_, and any extra command
line arguments. This user input is handled by the `bilby_pipe.main <main.txt>`_
module (which provides the command-line interface). It generates two types of
output, "DAG files" and a "summary webpage" (if requested). I.e., the top-level
workflow looks like this:

.. graphviz::

   digraph {
         rankdir="LR";
         "User input" -> "bilby_pipe.main";
         "bilby_pipe.main" -> "DAG files";
         "bilby_pipe.main" -> "summary webpage";
            }

Depending on the exact type of the job, the DAG may contain a number of jobs.
Typically, there are *generation* and *analysis* jobs. For a simple job, e.g.,
analysing a GraceDB candidate. There may be one generation job (to load the
JSON data from GraceDB, find relevant frame files and make PSDs) and one
analysis job (to run some sampler given some prior etc.). For cases with
multiple components (e.g., create an analysis n injections) things may be
more complicated. The logic for handling all of this is contained within the
`main <main.txt>`_ module.

In the most general case, there will be n parallell jobs with no inter-job
dependencies. Within each of these jobs, there is typically a structure in
the DAG as follows:

.. graphviz::

   digraph {
         rankdir="TD";
         "Data Generation" -> "Data Analysis 1";
         "Data Generation" -> "Data Analysis 2";
         "Data Generation" -> "...";
         "Data Generation" -> "Data Analysis M";
         "Data Analysis 1" -> "post-processing";
         "Data Analysis 2" -> "post-processing";
         "..." -> "post-processing";
         "Data Analysis N" -> "post-processing";
            }

Each Data Analysis job refers to a different way to analyse the same data. For
example, using different samplers, or different subsets of detectors. If there
are M Data Anlaysis jobs and N top-level jobs, there is MN jobs in total.

The "Data Generation" job uses the `bilby_pipe_generation
<data_generation.txt>`_ executable to create all the data which may be
analysed.

The "Data Analysis" jobs uses the `bilby_pipe_analysis
<data_analysis.txt>`_ executable to create all the data which may be
analysed.

See the table of contents below for an overview of the API.

Submodules API
--------------
.. toctree::
   :maxdepth: 2

   main
   data_generation
   data_analysis
   create_injections
   utils
